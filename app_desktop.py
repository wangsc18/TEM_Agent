#!/usr/bin/env python3
"""
TEMåŒäººæ¨æ¼”æ¨¡æ‹Ÿå™¨ - ä¸»åº”ç”¨å…¥å£
æ•´åˆåŒæ¨¡å‹æ¶æ„ + è¯­éŸ³äº¤äº’
"""
import tkinter as tk
import threading
import asyncio
from tkinter import messagebox

from config import *
from data.mock_data import MOCK_DATA, DYNAMIC_EVENT
from engines.realtime_voice_engine import RealtimeVoiceEngine
from engines.text_llm_engine import TextLLMEngine
from engines.mini_tts_engine import MiniTTSEngine
from ui.panels import LeftPanel, CenterPanel, RightPanel


class TEMSimulatorApp:
    """ä¸»åº”ç”¨æ§åˆ¶å™¨"""
    def __init__(self, root):
        self.root = root
        self.root.title(WINDOW_TITLE)
        self.root.geometry(WINDOW_GEOMETRY)

        self.current_phase = "INDIVIDUAL"

        # å¯¹è¯å†å²å’ŒèƒŒæ™¯æ•°æ®
        self.conversation_history = []
        self.background_data = MOCK_DATA
        self.personal_memo = ""

        # TEM ç³»ç»Ÿæç¤ºè¯
        self.base_system_prompt = """ä½ æ˜¯ä¸€åèˆªç©ºé£è¡Œå‘˜AIä¼™ä¼´ï¼Œæ­£åœ¨ä¸å¦ä¸€åé£è¡Œå‘˜è¿›è¡ŒTEMï¼ˆå¨èƒä¸å·®é”™ç®¡ç†ï¼‰æ¡ˆä¾‹è®¨è®ºã€‚

ã€æ ¸å¿ƒåŸåˆ™ - å®‰å…¨ç¬¬ä¸€ã€‘
åœ¨èˆªç©ºé¢†åŸŸï¼Œå‡†ç¡®æ€§å’Œå®‰å…¨æ€§é«˜äºä¸€åˆ‡ã€‚ä½ å¿…é¡»ä¸¥æ ¼éµå®ˆä»¥ä¸‹è§„åˆ™ï¼š

âŒ ç»å¯¹ç¦æ­¢çš„è¡Œä¸ºï¼š
1. ç¼–é€ æˆ–çŒœæµ‹ä¸“ä¸šæ•°æ®ï¼ˆå¦‚MELæ¡æ¬¾ã€æ€§èƒ½æ•°æ®ã€æ³•è§„æ¡æ¬¾ï¼‰
2. å¯¹ä¸ç¡®å®šçš„ä¸“ä¸šé—®é¢˜ç»™å‡ºæ¨¡ç³Šæˆ–çŒœæµ‹æ€§çš„å›ç­”
3. å›ç­”è¶…å‡ºä½ å½“å‰ä¿¡æ¯èŒƒå›´çš„ä¸“ä¸šé—®é¢˜

âœ… å¿…é¡»éµå®ˆçš„è¡Œä¸ºï¼š
1. å¦‚æœé—®é¢˜æ¶‰åŠå…·ä½“çš„ä¸“ä¸šçŸ¥è¯†ï¼ˆMELã€è¿è¡Œæ‰‹å†Œã€æ³•è§„ã€æ€§èƒ½è®¡ç®—ç­‰ï¼‰ï¼Œä½ å¿…é¡»ç«‹å³å›å¤"è®©æˆ‘æŸ¥æ‰¾ä¸€ä¸‹ç›¸å…³ä¿¡æ¯"
2. åªè®¨è®ºä½ å·²çŸ¥çš„ã€ç¡®å®šçš„ä¿¡æ¯
3. ç”¨å£è¯­åŒ–ã€ç®€çŸ­çš„æ–¹å¼äº¤æµï¼ˆ10-20å­—ï¼‰
4. é€‚å½“ä½¿ç”¨"å—¯"ã€"å¥½çš„"ç­‰å£è¯­åŒ–è¡¨è¾¾

ã€ä½•æ—¶å¿…é¡»è¯´"è®©æˆ‘æŸ¥æ‰¾ä¸€ä¸‹ç›¸å…³ä¿¡æ¯"ã€‘
- ç”¨æˆ·é—®åˆ°å…·ä½“çš„MELæ¡æ¬¾ã€é™åˆ¶ã€æ‰‹å†Œæ¡æ¬¾
- æ¶‰åŠæ€§èƒ½è®¡ç®—ã€é‡é‡é™åˆ¶ç­‰å…·ä½“æ•°å€¼
- éœ€è¦å¼•ç”¨æ³•è§„ã€è¿è¡Œæ ‡å‡†
- ä»»ä½•ä½ ä¸100%ç¡®å®šçš„ä¸“ä¸šé—®é¢˜

ã€ä½ å¯ä»¥ç›´æ¥å›ç­”çš„ã€‘
- ä¸€èˆ¬æ€§çš„å¨èƒè¯†åˆ«å’Œè®¨è®º
- åŸºäºå·²çŸ¥ä¿¡æ¯çš„è§‚å¯Ÿå’Œæ€»ç»“
- å¯¹è¯å¼•å¯¼å’Œç¡®è®¤æ€§é—®é¢˜"""

        # åˆå§‹åŒ–åŒå¼•æ“
        self.small_model = None  # Azure Realtime API
        self.big_model = None    # yunwu å¹³å°
        self._init_dual_engines()

        # --- UI é¢æ¿åˆå§‹åŒ– ---
        self.root.grid_rowconfigure(0, weight=1)
        self.root.grid_columnconfigure(0, weight=1)
        self.root.grid_columnconfigure(1, weight=3)
        self.root.grid_columnconfigure(2, weight=2)

        self.left_panel = LeftPanel(self.root, self)
        self.center_panel = CenterPanel(self.root, self)
        self.right_panel = RightPanel(self.root, self)

        self.left_panel.grid(row=0, column=0, sticky="nsew", padx=5, pady=5)
        self.center_panel.grid(row=0, column=1, sticky="nsew", padx=5, pady=5)
        self.right_panel.grid(row=0, column=2, sticky="nsew", padx=5, pady=5)

    def _init_dual_engines(self):
        """åˆå§‹åŒ–åŒå¼•æ“ï¼ˆå°æ¨¡å‹ + å¤§æ¨¡å‹ï¼‰"""
        try:
            # 1. åˆå§‹åŒ–å°æ¨¡å‹ï¼ˆæ ¹æ®é…ç½®å’Œå¯ç”¨æ€§è‡ªåŠ¨é€‰æ‹©ï¼‰
            self.small_model = None

            # è·å–å¼•æ“ä¼˜å…ˆçº§åˆ—è¡¨
            fallback_order = ENGINE_FALLBACK_ORDER if 'ENGINE_FALLBACK_ORDER' in globals() else ["realtime", "mini_tts"]

            # å¦‚æœ VOICE_MODE æ˜ç¡®æŒ‡å®šï¼Œä¼˜å…ˆå°è¯•è¯¥æ¨¡å¼
            if VOICE_MODE and VOICE_MODE not in fallback_order:
                fallback_order = [VOICE_MODE] + fallback_order
            elif VOICE_MODE and VOICE_MODE in fallback_order:
                # å°†æŒ‡å®šæ¨¡å¼ç§»åˆ°æœ€å‰é¢
                fallback_order = [VOICE_MODE] + [m for m in fallback_order if m != VOICE_MODE]

            print(f"[å°æ¨¡å‹] å°è¯•åˆå§‹åŒ–å¼•æ“ï¼Œä¼˜å…ˆçº§: {fallback_order}")

            for engine_type in fallback_order:
                if engine_type == "realtime":
                    # å°è¯• Azure Realtime API
                    if AZURE_OPENAI_ENDPOINT and AZURE_OPENAI_API_KEY:
                        try:
                            self.small_model = RealtimeVoiceEngine(
                                azure_endpoint=AZURE_OPENAI_ENDPOINT,
                                azure_api_key=AZURE_OPENAI_API_KEY,
                                deployment_name=AZURE_REALTIME_DEPLOYMENT,
                                voice=AUDIO_VOICE,
                                system_prompt=self.base_system_prompt,
                                callback_on_response_start=self._on_small_model_start,
                                callback_on_transcript_delta=self._on_small_model_delta,
                                callback_on_response_done=self._on_small_model_done,
                                callback_on_error=self._on_small_model_error
                            )
                            print(f"[å°æ¨¡å‹] âœ“ Azure Realtime API åˆå§‹åŒ–æˆåŠŸ")
                            break
                        except Exception as e:
                            print(f"[å°æ¨¡å‹] âš ï¸ Azure Realtime API åˆå§‹åŒ–å¤±è´¥: {e}")
                    else:
                        print(f"[å°æ¨¡å‹] âš ï¸ ç¼ºå°‘ Azure é…ç½®ï¼Œè·³è¿‡ Realtime API")

                elif engine_type == "mini_tts":
                    # å°è¯• Mini+TTS å¼•æ“
                    if OPENAI_API_KEY:
                        try:
                            self.small_model = MiniTTSEngine(
                                api_key=OPENAI_API_KEY,
                                base_url=CUSTOM_BASE_URL,
                                model=MINI_MODEL if 'MINI_MODEL' in globals() else "gpt-4o-mini",
                                voice=MINI_TTS_VOICE if 'MINI_TTS_VOICE' in globals() else "zh-CN-XiaoxiaoNeural",
                                system_prompt=self.base_system_prompt,
                                temperature=0.7,
                                max_tokens=MINI_TTS_MAX_TOKENS if 'MINI_TTS_MAX_TOKENS' in globals() else 1000,
                                callback_on_response_start=self._on_small_model_start,
                                callback_on_text_delta=self._on_small_model_delta,
                                callback_on_tts_sentence=self._on_tts_sentence,
                                callback_on_response_done=self._on_small_model_done,
                                callback_on_error=self._on_small_model_error
                            )
                            print(f"[å°æ¨¡å‹] âœ“ Mini+TTS å¼•æ“åˆå§‹åŒ–æˆåŠŸ")
                            break
                        except Exception as e:
                            print(f"[å°æ¨¡å‹] âš ï¸ Mini+TTS å¼•æ“åˆå§‹åŒ–å¤±è´¥: {e}")
                    else:
                        print(f"[å°æ¨¡å‹] âš ï¸ ç¼ºå°‘ OPENAI_API_KEYï¼Œè·³è¿‡ Mini+TTS")

            if not self.small_model:
                print("[å°æ¨¡å‹] âš ï¸ æ‰€æœ‰å°æ¨¡å‹å¼•æ“åˆå§‹åŒ–å¤±è´¥")

            # 2. åˆå§‹åŒ–å¤§æ¨¡å‹ï¼ˆyunwu å¹³å°ï¼‰
            if OPENAI_API_KEY:
                big_model_prompt = """ä½ æ˜¯èˆªç©ºé¢†åŸŸçš„ä¸“ä¸šæŠ€æœ¯é¡¾é—®ï¼Œæ“…é•¿TEMï¼ˆå¨èƒä¸å·®é”™ç®¡ç†ï¼‰åˆ†æã€‚
å½“è¢«é—®åˆ°å…·ä½“çš„ä¸“ä¸šé—®é¢˜æ—¶ï¼Œä½ éœ€è¦ï¼š
1. å¼•ç”¨ç›¸å…³çš„MELæ¡æ¬¾ã€æ‰‹å†Œè§„å®š
2. æä¾›è¯¦ç»†çš„åˆ†æå’Œå»ºè®®
3. è€ƒè™‘å®‰å…¨å› ç´ å’Œå¤‡ç”¨æ–¹æ¡ˆ
4. ç»™å‡ºå…·ä½“çš„æ“ä½œæ­¥éª¤"""

                self.big_model = TextLLMEngine(
                    api_key=OPENAI_API_KEY,
                    base_url=CUSTOM_BASE_URL,
                    model=BIG_MODEL,
                    system_prompt=big_model_prompt,
                    temperature=0.7,
                    max_tokens=2000,
                    callback_on_response_start=self._on_big_model_start,
                    callback_on_text_delta=self._on_big_model_delta,
                    callback_on_response_done=self._on_big_model_done,
                    callback_on_error=self._on_big_model_error
                )
                print("[å¤§æ¨¡å‹] yunwu å¹³å°åˆå§‹åŒ–æˆåŠŸ")
            else:
                print("[å¤§æ¨¡å‹] âš ï¸ ç¼ºå°‘ OPENAI_API_KEYï¼Œå¤§æ¨¡å‹ä¸å¯ç”¨")

            if not self.small_model and not self.big_model:
                raise ValueError("å°æ¨¡å‹å’Œå¤§æ¨¡å‹éƒ½æœªåˆå§‹åŒ–ï¼Œè¯·æ£€æŸ¥é…ç½®")

            print("[åŒå¼•æ“] åˆå§‹åŒ–å®Œæˆ")

        except Exception as e:
            print(f"[åŒå¼•æ“] åˆå§‹åŒ–å¤±è´¥: {e}")
            messagebox.showerror("é”™è¯¯", f"å¼•æ“åˆå§‹åŒ–å¤±è´¥ï¼š{str(e)}\nè¯·æ£€æŸ¥.envä¸­çš„APIé…ç½®")

    # === å°æ¨¡å‹å›è°ƒ ===
    def _on_small_model_start(self):
        """å°æ¨¡å‹å¼€å§‹å“åº”"""
        self._update_status("ğŸ”Š AIå›å¤ä¸­...", "speaking")

    def _on_small_model_delta(self, delta_text: str):
        """å°æ¨¡å‹æ–‡æœ¬å¢é‡"""
        self.root.after(0, lambda: self.right_panel.append_ai_message_streaming(delta_text))

    def _on_tts_sentence(self, sentence: str, index: int, status: str):
        """Mini+TTS å¥å­è½¬æ¢å›è°ƒ"""
        self.root.after(0, lambda: self.right_panel.update_tts_progress(sentence, index, status))

    def _on_small_model_done(self, full_response: str):
        """å°æ¨¡å‹å“åº”å®Œæˆ"""
        # æ·»åŠ åˆ°å¯¹è¯å†å²
        self.conversation_history.append({
            "role": "assistant",
            "content": full_response
        })

        # æ£€æŸ¥æ˜¯å¦è§¦å‘å¤§æ¨¡å‹
        trigger_keywords = ["æŸ¥æ‰¾", "æŸ¥é˜…", "æŸ¥è¯¢", "æœç´¢", "è®©æˆ‘"]
        if any(keyword in full_response for keyword in trigger_keywords):
            print("[è§¦å‘æ£€æµ‹] æ£€æµ‹åˆ°è§¦å‘è¯ï¼Œå¯åŠ¨å¤§æ¨¡å‹")
            self._trigger_big_model(self.conversation_history[-2]["content"])  # ç”¨æˆ·æœ€åçš„é—®é¢˜
        else:
            self._update_status("âœ“ å®Œæˆ", "success")

    def _on_small_model_error(self, error_msg: str):
        """å°æ¨¡å‹é”™è¯¯"""
        self._update_status(f"âŒ å°æ¨¡å‹é”™è¯¯: {error_msg}", "error")

    # === å¤§æ¨¡å‹å›è°ƒ ===
    def _on_big_model_start(self):
        """å¤§æ¨¡å‹å¼€å§‹å“åº”"""
        self._update_status("ğŸ§  ä¸“å®¶åˆ†æä¸­...", "processing")
        self.root.after(0, lambda: self.right_panel.show_expert_avatar())

    def _on_big_model_delta(self, delta_text: str):
        """å¤§æ¨¡å‹æ–‡æœ¬å¢é‡"""
        self.root.after(0, lambda: self.right_panel.append_ai_message_streaming(delta_text))

    def _on_big_model_done(self, full_response: str):
        """å¤§æ¨¡å‹å“åº”å®Œæˆ"""
        # æ·»åŠ åˆ°å¯¹è¯å†å²
        self.conversation_history.append({
            "role": "assistant",
            "content": "æ ¹æ®è¯¦ç»†åˆ†æï¼Œ" + full_response
        })
        self._update_status("âœ“ ä¸“å®¶åˆ†æå®Œæˆ", "success")

    def _on_big_model_error(self, error_msg: str):
        """å¤§æ¨¡å‹é”™è¯¯"""
        self._update_status(f"âŒ å¤§æ¨¡å‹é”™è¯¯: {error_msg}", "error")

    # === ç»Ÿä¸€æ¥å£æ–¹æ³• ===
    def process_user_message(self, user_message: str):
        """å¤„ç†ç”¨æˆ·æ¶ˆæ¯ï¼ˆç»Ÿä¸€å…¥å£ï¼‰"""
        # æ·»åŠ ç”¨æˆ·æ¶ˆæ¯åˆ°å†å²
        self.conversation_history.append({
            "role": "user",
            "content": user_message
        })

        # è°ƒç”¨å°æ¨¡å‹
        if self.small_model:
            def run_small_model():
                loop = asyncio.new_event_loop()
                asyncio.set_event_loop(loop)
                try:
                    # è·å–å¯¹è¯å†å²ï¼ˆæ’é™¤æœ€åä¸€æ¡ï¼Œå› ä¸ºå·²åœ¨ chat ä¸­æ·»åŠ ï¼‰
                    history = self.conversation_history[:-1]
                    loop.run_until_complete(
                        self.small_model.chat(user_message, conversation_history=history)
                    )
                except Exception as e:
                    print(f"[å°æ¨¡å‹çº¿ç¨‹] é”™è¯¯: {e}")
                finally:
                    loop.close()

            thread = threading.Thread(target=run_small_model, daemon=True)
            thread.start()
        else:
            messagebox.showwarning("è­¦å‘Š", "å°æ¨¡å‹æœªåˆå§‹åŒ–")

    def _trigger_big_model(self, user_question: str):
        """è§¦å‘å¤§æ¨¡å‹æ·±åº¦åˆ†æ"""
        if not self.big_model:
            print("[å¤§æ¨¡å‹] æœªåˆå§‹åŒ–ï¼Œè·³è¿‡")
            return

        def run_big_model():
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)
            try:
                # ä½¿ç”¨æ·±åº¦åˆ†ææ–¹æ³•
                loop.run_until_complete(
                    self.big_model.analyze_with_context(
                        user_question=user_question,
                        conversation_history=self.conversation_history[:-1],
                        background_data=self.background_data,
                        personal_memo=self.personal_memo
                    )
                )
            except Exception as e:
                print(f"[å¤§æ¨¡å‹çº¿ç¨‹] é”™è¯¯: {e}")
            finally:
                loop.close()

        thread = threading.Thread(target=run_big_model, daemon=True)
        thread.start()

    def set_personal_memo(self, memo: str):
        """è®¾ç½®ä¸ªäººå¤‡å¿˜å½•"""
        self.personal_memo = memo

    def _update_status(self, text: str, status_type: str):
        """æ›´æ–°çŠ¶æ€"""
        def update():
            self.right_panel.update_voice_status(text, status_type)

            # æ§åˆ¶å¤´åƒåŠ¨ç”»
            if not hasattr(self.right_panel, 'user_avatar'):
                return

            if status_type == "speaking":
                self.right_panel.ai_avatar.start_speaking()
                self.right_panel.user_avatar.stop_speaking()
                if hasattr(self.right_panel, 'expert_avatar'):
                    self.right_panel.expert_avatar.stop_speaking()
            elif status_type == "processing" and "ä¸“å®¶" in text:
                if hasattr(self.right_panel, 'expert_avatar'):
                    self.right_panel.expert_avatar.start_speaking()
                self.right_panel.ai_avatar.stop_speaking()
                self.right_panel.user_avatar.stop_speaking()
            elif status_type in ["success", "error"]:
                self.right_panel.ai_avatar.stop_speaking()
                self.right_panel.user_avatar.stop_speaking()
                if hasattr(self.right_panel, 'expert_avatar'):
                    self.right_panel.expert_avatar.stop_speaking()
                    self.right_panel.hide_expert_avatar()
                if status_type == "success":
                    self.right_panel._end_ai_streaming()

        self.root.after(0, update)

    def on_voice_input_button_click(self):
        """è¯­éŸ³è¾“å…¥æŒ‰é’®è¢«ç‚¹å‡»"""
        # TODO: è¯­éŸ³è¾“å…¥åŠŸèƒ½æš‚æœªè¿ç§»åˆ°æ–°å¼•æ“
        messagebox.showinfo("æç¤º", "è¯­éŸ³è¾“å…¥åŠŸèƒ½æš‚æœªå®ç°ï¼Œè¯·ä½¿ç”¨æ–‡æœ¬è¾“å…¥")

    def on_info_button_click(self, info_type):
        """å½“å·¦ä¾§ä¿¡æ¯æŒ‰é’®è¢«ç‚¹å‡»æ—¶"""
        print(f"[äº‹ä»¶] ç”¨æˆ·è¯·æ±‚æŸ¥çœ‹ '{info_type}'")
        data_to_display = MOCK_DATA.get(info_type, "æœªæ‰¾åˆ°ä¿¡æ¯ã€‚")
        self.center_panel.display_info(info_type, data_to_display)

    def start_team_discussion(self):
        """åˆ‡æ¢åˆ°åŒäººåä½œé˜¶æ®µ"""
        if self.current_phase == "INDIVIDUAL":
            print("[äº‹ä»¶] åˆ‡æ¢åˆ°åä½œè®¨è®ºé˜¶æ®µã€‚")

            # 1. ä¿å­˜ä¸ªäººå¨èƒå¤‡å¿˜å½•å†…å®¹
            personal_threats = self.right_panel.get_personal_threats()

            # 2. å°†ä¸ªäººå¨èƒå¤‡å¿˜å½•ä¼ é€’ç»™å¤§æ¨¡å‹ï¼ˆç”¨äºæ·±åº¦åˆ†æï¼‰
            self.set_personal_memo(personal_threats)

            # 3. åˆ‡æ¢åˆ°åä½œé˜¶æ®µ
            self.current_phase = "COLLABORATIVE"
            self.right_panel.setup_collaborative_view()
            self.left_panel.disable_buttons()

            # 4. åœ¨ä¸­é—´é¢æ¿æ˜¾ç¤ºä¸ªäººå¨èƒæ€»ç»“
            self.center_panel.display_personal_threats(personal_threats)

            # 5. 3ç§’åæ³¨å…¥åŠ¨æ€äº‹ä»¶
            self.root.after(3000, self.inject_dynamic_event)

    def inject_dynamic_event(self):
        """æ³¨å…¥åŠ¨æ€äº‹ä»¶"""
        print("[äº‹ä»¶] æ³¨å…¥åŠ¨æ€äº‹ä»¶ï¼")
        messagebox.showwarning(DYNAMIC_EVENT["title"], DYNAMIC_EVENT["message"])


def main():
    """ä¸»ç¨‹åºå…¥å£"""
    root = tk.Tk()
    app = TEMSimulatorApp(root)
    root.mainloop()


if __name__ == "__main__":
    main()
