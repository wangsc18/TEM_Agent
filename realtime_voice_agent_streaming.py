#!/usr/bin/env python3
"""
Real-time Voice Interaction Agent - Ultra-Fast Streaming Version
è¶…å¿«é€Ÿæµå¼ç‰ˆæœ¬ï¼šæ¿€è¿›åˆ†å— + æœ¬åœ°TTS
"""

import os
import time
import asyncio
import tempfile
import subprocess
from typing import Optional, AsyncIterator, Literal
import wave
import re

import numpy as np
import sounddevice as sd
from openai import AsyncOpenAI
from dotenv import load_dotenv

load_dotenv()


class UltraFastMetrics:
    """è¶…å¿«é€Ÿæ€§èƒ½æŒ‡æ ‡"""

    def __init__(self):
        self.reset()

    def reset(self):
        self.recording_time = 0.0
        self.stt_time = 0.0
        self.llm_first_token_time = 0.0
        self.first_chunk_tts_time = 0.0
        self.first_audio_play_time = 0.0
        self.total_time = 0.0
        self.transcribed_text = ""
        self.llm_response = ""
        self.chunk_count = 0
        self.chunk_times = []

    def print_summary(self):
        print("\n" + "="*60)
        print("è¶…å¿«é€Ÿæµå¼ - æ€§èƒ½æŒ‡æ ‡")
        print("="*60)
        print(f"å½•éŸ³:                {self.recording_time:.2f}s")
        print(f"STT:                 {self.stt_time:.2f}s")
        print(f"âš¡ é¦–ä¸ªtoken:        {self.llm_first_token_time:.2f}s")
        print(f"âš¡ é¦–å—TTS:          {self.first_chunk_tts_time:.2f}s")
        print(f"âš¡ é¦–æ¬¡æ’­æ”¾:         {self.first_audio_play_time:.2f}s (å…³é”®)")
        print(f"æ€»è€—æ—¶:              {self.total_time:.2f}s")
        print(f"å¤„ç†æ–‡æœ¬å—æ•°:        {self.chunk_count}")
        if self.chunk_times:
            avg = sum(self.chunk_times) / len(self.chunk_times)
            print(f"å¹³å‡æ¯å—è€—æ—¶:        {avg:.2f}s")
        print("="*60)
        if self.transcribed_text:
            print(f"\nç”¨æˆ·: {self.transcribed_text}")
        if self.llm_response:
            print(f"åŠ©æ‰‹: {self.llm_response}")
        print()


class UltraFastVoiceAgent:
    """è¶…å¿«é€Ÿè¯­éŸ³äº¤äº’Agent"""

    def __init__(
        self,
        api_key: Optional[str] = None,
        model: str = "gpt-4o-mini",
        stt_model: str = "whisper-1",
        tts_engine: Literal["local", "edge", "openai"] = "local",
        tts_voice: str = "nova"
    ):
        """
        åˆå§‹åŒ–è¶…å¿«é€Ÿè¯­éŸ³äº¤äº’Agent

        Args:
            tts_engine: TTSå¼•æ“é€‰æ‹©
                - "local": macOS sayå‘½ä»¤ï¼ˆæœ€å¿«ï¼Œ~0.1sï¼‰
                - "edge": edge-ttsï¼ˆå¿«ï¼Œ~0.5sï¼Œéœ€è¦å®‰è£…ï¼‰
                - "openai": OpenAI TTSï¼ˆæ…¢ï¼Œ~2sï¼Œè´¨é‡æœ€å¥½ï¼‰
        """
        self.api_key = api_key or os.getenv("OPENAI_API_KEY")
        if not self.api_key:
            raise ValueError("æœªæ‰¾åˆ° OPENAI_API_KEY")

        self.client = AsyncOpenAI(api_key=self.api_key)
        self.model = model
        self.stt_model = stt_model
        self.tts_engine = tts_engine
        self.tts_voice = tts_voice

        self.conversation_history = [
            {
                "role": "system",
                "content": """ä½ æ˜¯ä¸€ä¸ªå‹å¥½ã€è‡ªç„¶çš„AIè¯­éŸ³åŠ©æ‰‹ã€‚

é‡è¦è¦æ±‚ï¼š
1. ç”¨å£è¯­åŒ–çš„æ–¹å¼è¯´è¯ï¼Œå°±åƒæœ‹å‹èŠå¤©ä¸€æ ·
2. å¤šç”¨"å—¯"ã€"å•Š"ã€"å‘¢"ã€"å“¦"ç­‰è¯­æ°”è¯ï¼Œè®©å¯¹è¯æ›´è‡ªç„¶
3. å¥å­è¦çŸ­ï¼Œæ¯å¥è¯10-20ä¸ªå­—
4. é¿å…ä½¿ç”¨ä¹¦é¢è¯­ï¼Œç”¨æ—¥å¸¸å£è¯­
5. å¯ä»¥é€‚å½“é‡å¤æˆ–åœé¡¿ï¼Œå°±åƒçœŸäººè¯´è¯
6. è¡¨è¾¾æƒ…æ„Ÿï¼Œæ¯”å¦‚"å¤ªæ£’äº†"ã€"æˆ‘æ˜ç™½äº†"ã€"è®©æˆ‘æƒ³æƒ³"

ç¤ºä¾‹ï¼š
âŒ ä¹¦é¢ï¼šæˆ‘å¯ä»¥ä¸ºæ‚¨æä¾›ç›¸å…³ä¿¡æ¯ã€‚
âœ… å£è¯­ï¼šå¥½çš„ï¼Œæˆ‘æ¥å¸®ä½ çœ‹çœ‹å•Šã€‚

âŒ ä¹¦é¢ï¼šå…³äºè¿™ä¸ªé—®é¢˜ï¼Œæœ‰ä»¥ä¸‹å‡ ç‚¹éœ€è¦è¯´æ˜ã€‚
âœ… å£è¯­ï¼šå—¯ï¼Œè¿™ä¸ªé—®é¢˜å‘¢ï¼Œæˆ‘è§‰å¾—æ˜¯è¿™æ ·çš„ã€‚

è®°ä½ï¼šç®€çŸ­ã€å£è¯­ã€è‡ªç„¶ï¼"""
            }
        ]

        self.sample_rate = 16000
        self.channels = 1
        self.metrics = UltraFastMetrics()
        self.audio_queue = asyncio.Queue()
        self.playback_active = False

        # éªŒè¯TTSå¼•æ“
        self._check_tts_engine()

    def _check_tts_engine(self):
        """æ£€æŸ¥TTSå¼•æ“æ˜¯å¦å¯ç”¨"""
        if self.tts_engine == "local":
            # æ£€æŸ¥macOS sayå‘½ä»¤
            result = subprocess.run(["which", "say"], capture_output=True)
            if result.returncode != 0:
                print("âš ï¸  è­¦å‘Š: æœªæ‰¾åˆ°macOS sayå‘½ä»¤ï¼Œå°†ä½¿ç”¨OpenAI TTS")
                self.tts_engine = "openai"
            else:
                print("âœ“ ä½¿ç”¨æœ¬åœ°TTS (macOS say) - è¶…ä½å»¶è¿Ÿ")

        elif self.tts_engine == "edge":
            # æ£€æŸ¥edge-tts
            result = subprocess.run(["which", "edge-tts"], capture_output=True)
            if result.returncode != 0:
                print("âš ï¸  è­¦å‘Š: æœªå®‰è£…edge-ttsï¼Œå°†ä½¿ç”¨OpenAI TTS")
                print("   å®‰è£…: pip install edge-tts")
                self.tts_engine = "openai"
            else:
                print("âœ“ ä½¿ç”¨Edge TTS - å¿«é€Ÿä¸”é«˜è´¨é‡")

        elif self.tts_engine == "openai":
            print("âœ“ ä½¿ç”¨OpenAI TTS - æœ€é«˜è´¨é‡ä½†è¾ƒæ…¢")

    def _get_volume_bar(self, volume: float, bar_length: int = 30) -> str:
        filled = int(volume * bar_length)
        bar = "â–ˆ" * filled + "â–‘" * (bar_length - filled)
        percentage = int(volume * 100)
        return f"|{bar}| {percentage}%"

    def record_audio(
        self,
        duration: float = 5.0,
        silence_threshold: float = 0.015,
        min_voice_energy: float = 0.02,
        show_volume: bool = True
    ) -> Optional[str]:
        """å½•åˆ¶éŸ³é¢‘ï¼ˆç®€åŒ–ç‰ˆï¼‰"""
        print(f"\nğŸ¤ å½•éŸ³ä¸­...")

        start_time = time.time()
        recording = []
        silence_duration = 0
        max_silence = 1.5
        has_speech = False

        def audio_callback(indata, frames, time_info, status):
            recording.append(indata.copy())

        with sd.InputStream(
            samplerate=self.sample_rate,
            channels=self.channels,
            callback=audio_callback,
            dtype=np.float32
        ):
            chunk_duration = 0.1
            chunks = int(duration / chunk_duration)

            for _ in range(chunks):
                sd.sleep(int(chunk_duration * 1000))

                if len(recording) > 0:
                    recent_chunk = recording[-1]
                    volume = np.abs(recent_chunk).mean()

                    if show_volume and len(recording) % 5 == 0:
                        normalized_volume = min(volume / 0.1, 1.0)
                        print(f"\r{self._get_volume_bar(normalized_volume)}", end="", flush=True)

                    if volume > min_voice_energy:
                        has_speech = True

                    if volume < silence_threshold:
                        silence_duration += chunk_duration
                        if silence_duration >= max_silence and has_speech and len(recording) > 10:
                            break
                    else:
                        silence_duration = 0

        if show_volume:
            print()

        self.metrics.recording_time = time.time() - start_time

        if not recording or not has_speech:
            print("âŒ å½•éŸ³å¤±è´¥")
            return None

        audio_data = np.concatenate(recording, axis=0)
        rms = np.sqrt(np.mean(audio_data ** 2))

        if rms < 0.005:
            print("âŒ éŸ³é‡å¤ªä½")
            return None

        print(f"âœ“ å½•éŸ³å®Œæˆ ({self.metrics.recording_time:.2f}s)")

        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".wav")
        with wave.open(temp_file.name, 'wb') as wf:
            wf.setnchannels(self.channels)
            wf.setsampwidth(2)
            wf.setframerate(self.sample_rate)
            audio_int16 = (audio_data * 32767).astype(np.int16)
            wf.writeframes(audio_int16.tobytes())

        return temp_file.name

    async def speech_to_text(self, audio_file_path: str) -> str:
        """è¯­éŸ³è½¬æ–‡æœ¬"""
        print("ğŸ”„ è¯†åˆ«ä¸­...")
        start_time = time.time()

        with open(audio_file_path, "rb") as audio_file:
            transcript = await self.client.audio.transcriptions.create(
                model=self.stt_model,
                file=audio_file,
                language="zh"
            )

        self.metrics.stt_time = time.time() - start_time
        text = transcript.text
        self.metrics.transcribed_text = text

        print(f"âœ“ è¯†åˆ«: {text}")
        return text

    def _chunk_text_aggressively(self, text: str, max_chars: int = 20) -> list[str]:
        """
        æ¿€è¿›çš„æ–‡æœ¬åˆ†å—ç­–ç•¥
        æ¯10-20ä¸ªå­—å°±åˆ†ä¸€å—ï¼Œä¸ç­‰å®Œæ•´å¥å­

        Args:
            text: è¾“å…¥æ–‡æœ¬
            max_chars: æ¯å—æœ€å¤§å­—ç¬¦æ•°

        Returns:
            æ–‡æœ¬å—åˆ—è¡¨
        """
        chunks = []
        current_chunk = ""

        # æŒ‰å­—ç¬¦å’Œæ ‡ç‚¹åˆ†å—
        for char in text:
            current_chunk += char

            # é‡åˆ°æ ‡ç‚¹æˆ–è¾¾åˆ°æœ€å¤§é•¿åº¦å°±åˆ†å—
            is_punctuation = char in 'ï¼Œã€‚ï¼ï¼Ÿã€ï¼›ï¼š,. !?;:\n'
            is_max_length = len(current_chunk) >= max_chars

            if (is_punctuation or is_max_length) and len(current_chunk.strip()) > 3:
                chunks.append(current_chunk.strip())
                current_chunk = ""

        # æ·»åŠ å‰©ä½™éƒ¨åˆ†
        if current_chunk.strip():
            chunks.append(current_chunk.strip())

        return chunks

    async def stream_llm_response(self, user_input: str) -> AsyncIterator[str]:
        """æµå¼è·å–LLMå“åº”"""
        print("ğŸ¤– ç”Ÿæˆä¸­...")

        self.conversation_history.append({"role": "user", "content": user_input})

        llm_start = time.time()
        first_token = True
        full_response = ""

        stream = await self.client.chat.completions.create(
            model=self.model,
            messages=self.conversation_history,
            temperature=0.7,
            max_tokens=300,  # é™åˆ¶é•¿åº¦ï¼Œé¼“åŠ±ç®€çŸ­å›å¤
            stream=True
        )

        async for chunk in stream:
            if chunk.choices[0].delta.content:
                content = chunk.choices[0].delta.content

                if first_token:
                    self.metrics.llm_first_token_time = time.time() - llm_start
                    print(f"âš¡ é¦–token: {self.metrics.llm_first_token_time:.2f}s")
                    first_token = False

                full_response += content
                yield content

        self.metrics.llm_response = full_response
        self.conversation_history.append({"role": "assistant", "content": full_response})

    async def text_to_speech_local(self, text: str) -> str:
        """æœ¬åœ°TTS (macOS sayå‘½ä»¤) - è¶…å¿«"""
        # ä½¿ç”¨.m4aæ ¼å¼æ›´å…¼å®¹
        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".m4a")
        temp_file.close()

        try:
            # ä½¿ç”¨macOS sayå‘½ä»¤
            # -v Tingting ä¸­æ–‡å¥³å£°ï¼ˆæ³¨æ„ï¼šæ— è¿å­—ç¬¦ï¼‰
            # --data-format=LEF32@22050 ä½¿ç”¨å…¼å®¹æ ¼å¼
            process = await asyncio.create_subprocess_exec(
                "say",
                "-v", "Tingting",  # ä¸­æ–‡è¯­éŸ³ï¼ˆå©·å©·ï¼‰
                "-o", temp_file.name,
                "--data-format=LEF32@22050",  # æŒ‡å®šæ ¼å¼
                text,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            _, stderr = await process.communicate()

            # æ£€æŸ¥æ˜¯å¦æˆåŠŸ
            if process.returncode != 0:
                print(f"âš ï¸  sayå‘½ä»¤é”™è¯¯: {stderr.decode()}")
                # æ¸…ç†å¤±è´¥çš„æ–‡ä»¶
                if os.path.exists(temp_file.name):
                    os.unlink(temp_file.name)
                return None

            # ç¡®ä¿æ–‡ä»¶å­˜åœ¨
            if not os.path.exists(temp_file.name):
                print(f"âš ï¸  éŸ³é¢‘æ–‡ä»¶æœªç”Ÿæˆ")
                return None

            return temp_file.name

        except Exception as e:
            print(f"âš ï¸  æœ¬åœ°TTSé”™è¯¯: {e}")
            if os.path.exists(temp_file.name):
                os.unlink(temp_file.name)
            return None

    async def text_to_speech_edge(self, text: str) -> str:
        """Edge TTS - å¿«é€Ÿä¸”é«˜è´¨é‡"""
        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3")
        temp_file.close()

        try:
            # ä½¿ç”¨edge-ttsï¼Œæ·»åŠ è¯­é€Ÿå’ŒéŸ³è°ƒå‚æ•°è®©è¯­éŸ³æ›´è‡ªç„¶
            # zh-CN-XiaoxiaoNeural - å¥³å£°ï¼ˆæ¸©æŸ”è‡ªç„¶ï¼‰
            # zh-CN-YunxiNeural - ç”·å£°ï¼ˆæ›´æœ‰æ´»åŠ›ï¼‰
            # --rate +10% ç¨å¿«ä¸€ç‚¹ï¼ˆæ›´æ¥è¿‘çœŸäººè¯´è¯ï¼‰
            # --pitch +5Hz ç¨å¾®æé«˜éŸ³è°ƒï¼ˆæ›´æœ‰æƒ…æ„Ÿï¼‰
            process = await asyncio.create_subprocess_exec(
                "edge-tts",
                "--voice", "zh-CN-XiaoxiaoNeural",  # å¯é€‰: YunxiNeural (ç”·å£°)
                "--rate", "+10%",  # è¯­é€ŸåŠ å¿«10%
                "--pitch", "+5Hz",  # éŸ³è°ƒæé«˜5Hz
                "--text", text,
                "--write-media", temp_file.name,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            _, stderr = await process.communicate()

            # æ£€æŸ¥æ˜¯å¦æˆåŠŸ
            if process.returncode != 0:
                print(f"âš ï¸  Edge TTSé”™è¯¯: {stderr.decode()}")
                if os.path.exists(temp_file.name):
                    os.unlink(temp_file.name)
                return None

            if not os.path.exists(temp_file.name):
                print(f"âš ï¸  éŸ³é¢‘æ–‡ä»¶æœªç”Ÿæˆ")
                return None

            return temp_file.name

        except Exception as e:
            print(f"âš ï¸  Edge TTSé”™è¯¯: {e}")
            if os.path.exists(temp_file.name):
                os.unlink(temp_file.name)
            return None

    async def text_to_speech_openai(self, text: str) -> str:
        """OpenAI TTS - é«˜è´¨é‡ä½†è¾ƒæ…¢"""
        response = await self.client.audio.speech.create(
            model="tts-1",  # ä½¿ç”¨æ›´å¿«çš„æ¨¡å‹
            voice=self.tts_voice,
            input=text,
            response_format="mp3"
        )

        temp_file = tempfile.NamedTemporaryFile(delete=False, suffix=".mp3")
        temp_file.write(response.content)
        temp_file.close()

        return temp_file.name

    async def text_to_speech(self, text: str) -> Optional[str]:
        """æ ¹æ®é…ç½®é€‰æ‹©TTSå¼•æ“"""
        if self.tts_engine == "local":
            return await self.text_to_speech_local(text)
        elif self.tts_engine == "edge":
            return await self.text_to_speech_edge(text)
        else:
            return await self.text_to_speech_openai(text)

    def play_audio_sync(self, audio_file_path: str):
        """åŒæ­¥æ’­æ”¾éŸ³é¢‘"""
        try:
            result = os.system(f'afplay "{audio_file_path}"')
            if result != 0:
                print(f"âš ï¸  æ’­æ”¾å¤±è´¥: {audio_file_path}")
        except Exception as e:
            print(f"âš ï¸  æ’­æ”¾é”™è¯¯: {e}")

    async def audio_player_worker(self):
        """éŸ³é¢‘æ’­æ”¾å·¥ä½œçº¿ç¨‹"""
        while self.playback_active:
            try:
                audio_file = await asyncio.wait_for(self.audio_queue.get(), timeout=0.5)

                if audio_file is None:  # ç»“æŸä¿¡å·
                    break

                # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦æœ‰æ•ˆ
                if audio_file and os.path.exists(audio_file):
                    loop = asyncio.get_event_loop()
                    await loop.run_in_executor(None, self.play_audio_sync, audio_file)

                    # æ’­æ”¾å®Œæˆååˆ é™¤
                    try:
                        os.unlink(audio_file)
                    except:
                        pass

            except asyncio.TimeoutError:
                continue
            except Exception as e:
                print(f"âš ï¸  æ’­æ”¾é˜Ÿåˆ—é”™è¯¯: {e}")

    async def process_ultra_fast_voice_input(self, recording_duration: float = 5.0):
        """è¶…å¿«é€Ÿè¯­éŸ³äº¤äº’å¤„ç†"""
        self.metrics.reset()
        total_start = time.time()

        audio_file = None

        try:
            # 1. å½•éŸ³
            audio_file = self.record_audio(duration=recording_duration)
            if audio_file is None:
                return

            # 2. STT
            user_text = await self.speech_to_text(audio_file)
            if not user_text.strip():
                return

            # 3. å¯åŠ¨æ’­æ”¾çº¿ç¨‹
            self.playback_active = True
            player_task = asyncio.create_task(self.audio_player_worker())

            # 4. æµå¼LLM + æ¿€è¿›åˆ†å—TTS
            buffer = ""
            chunk_index = 0
            first_audio_played = False

            print("\n" + "-"*40)

            async for token in self.stream_llm_response(user_text):
                buffer += token
                print(token, end="", flush=True)

                # æ¿€è¿›åˆ†å—ç­–ç•¥ï¼šæ¯15-20ä¸ªå­—ç¬¦å°±å¤„ç†ä¸€æ¬¡
                chunks = self._chunk_text_aggressively(buffer, max_chars=20)

                # å¤„ç†é™¤æœ€åä¸€ä¸ªä¹‹å¤–çš„æ‰€æœ‰å—ï¼ˆæœ€åä¸€ä¸ªå¯èƒ½ä¸å®Œæ•´ï¼‰
                for i in range(len(chunks) - 1):
                    chunk = chunks[i]
                    if len(chunk) > 2:  # è‡³å°‘3ä¸ªå­—ç¬¦æ‰å¤„ç†
                        chunk_start = time.time()

                        if chunk_index == 0:
                            tts_start = time.time()

                        # TTSè½¬æ¢
                        audio_file_path = await self.text_to_speech(chunk)

                        # è·³è¿‡å¤±è´¥çš„TTS
                        if audio_file_path is None:
                            continue

                        if chunk_index == 0:
                            self.metrics.first_chunk_tts_time = time.time() - tts_start
                            print(f"\nâš¡ é¦–å—TTS: {self.metrics.first_chunk_tts_time:.2f}s")

                        # åŠ å…¥æ’­æ”¾é˜Ÿåˆ—
                        await self.audio_queue.put(audio_file_path)

                        if not first_audio_played:
                            self.metrics.first_audio_play_time = time.time() - total_start
                            print(f"âš¡ é¦–æ¬¡æ’­æ”¾: {self.metrics.first_audio_play_time:.2f}s")
                            first_audio_played = True

                        chunk_time = time.time() - chunk_start
                        self.metrics.chunk_times.append(chunk_time)
                        chunk_index += 1

                # ä¿ç•™æœ€åä¸€ä¸ªå¯èƒ½ä¸å®Œæ•´çš„å—
                buffer = chunks[-1] if chunks else ""

            print("\n" + "-"*40)

            # å¤„ç†å‰©ä½™buffer
            if buffer.strip() and len(buffer.strip()) > 2:
                audio_file_path = await self.text_to_speech(buffer.strip())

                if audio_file_path is not None:
                    await self.audio_queue.put(audio_file_path)

                    if not first_audio_played:
                        self.metrics.first_audio_play_time = time.time() - total_start

                    chunk_index += 1

            self.metrics.chunk_count = chunk_index

            # å‘é€ç»“æŸä¿¡å·
            await self.audio_queue.put(None)
            await player_task

            self.metrics.total_time = time.time() - total_start
            self.metrics.print_summary()

        finally:
            if audio_file and os.path.exists(audio_file):
                os.unlink(audio_file)
            self.playback_active = False

    async def run_interactive_loop(self):
        """è¿è¡Œäº¤äº’å¼å¾ªç¯"""
        print("\n" + "="*60)
        print("è¶…å¿«é€Ÿå®æ—¶è¯­éŸ³äº¤äº’Agent")
        print("="*60)
        print(f"TTSå¼•æ“: {self.tts_engine.upper()}")
        print("ç‰¹æ€§:")
        print("âœ¨ æ¿€è¿›æ–‡æœ¬åˆ†å— - æ¯10-20å­—ä¸€å—")
        print(f"âœ¨ {'æœ¬åœ°' if self.tts_engine == 'local' else 'å¿«é€Ÿ'}TTS - æä½å»¶è¿Ÿ")
        print("âœ¨ è¾¹ç”Ÿæˆè¾¹æ’­æ”¾ - æ¥è¿‘å®æ—¶")
        print("="*60 + "\n")

        while True:
            user_input = input("æŒ‰å›è½¦å¼€å§‹ (quité€€å‡º): ").strip().lower()

            if user_input in ['quit', 'exit', 'q']:
                print("\nğŸ‘‹ å†è§ï¼")
                break

            await self.process_ultra_fast_voice_input()


async def main():
    """ä¸»å‡½æ•°"""
    try:
        # åˆ›å»ºè¶…å¿«é€Ÿagent
        # tts_engineå¯é€‰: "local", "edge", "openai"
        agent = UltraFastVoiceAgent(
            model="gpt-4o-mini",
            tts_engine="edge",  # ä½¿ç”¨æœ¬åœ°TTSè·å¾—æœ€å¿«é€Ÿåº¦
            tts_voice="nova"
        )

        await agent.run_interactive_loop()

    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ ç¨‹åºå·²ä¸­æ–­")
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())
