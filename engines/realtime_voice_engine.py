#!/usr/bin/env python3
"""
Azure Realtime API è¯­éŸ³å¼•æ“ - å°æ¨¡å‹ä¸“ç”¨
æµå¼éŸ³é¢‘è¾“å…¥è¾“å‡ºï¼Œè¶…ä½å»¶è¿Ÿ
"""
import os
import base64
import asyncio
from typing import Optional

import numpy as np
import sounddevice as sd
from openai import AsyncOpenAI


class RealtimeVoiceEngine:
    """Azure Realtime API è¯­éŸ³å¼•æ“ï¼ˆå°æ¨¡å‹ï¼‰"""

    def __init__(
        self,
        azure_endpoint: str,
        azure_api_key: str,
        deployment_name: str = "gpt-realtime-mini",
        voice: str = "alloy",
        system_prompt: str = "",
        callback_on_response_start=None,
        callback_on_audio_chunk=None,
        callback_on_transcript_delta=None,
        callback_on_response_done=None,
        callback_on_error=None
    ):
        """
        åˆå§‹åŒ– Realtime è¯­éŸ³å¼•æ“

        Args:
            azure_endpoint: Azure OpenAI ç«¯ç‚¹
            azure_api_key: Azure API å¯†é’¥
            deployment_name: éƒ¨ç½²åç§°
            voice: è¯­éŸ³ç±»å‹ (alloy, echo, shimmer)
            system_prompt: ç³»ç»Ÿæç¤ºè¯
            callback_on_response_start: å“åº”å¼€å§‹å›è°ƒ
            callback_on_audio_chunk: éŸ³é¢‘å—æ¥æ”¶å›è°ƒ (audio_data)
            callback_on_transcript_delta: è½¬å½•æ–‡æœ¬å¢é‡å›è°ƒ (delta_text)
            callback_on_response_done: å“åº”å®Œæˆå›è°ƒ (full_transcript)
            callback_on_error: é”™è¯¯å›è°ƒ (error_message)
        """
        self.azure_endpoint = azure_endpoint
        self.azure_api_key = azure_api_key
        self.deployment_name = deployment_name
        self.voice = voice
        self.system_prompt = system_prompt

        # å›è°ƒå‡½æ•°
        self.callback_on_response_start = callback_on_response_start
        self.callback_on_audio_chunk = callback_on_audio_chunk
        self.callback_on_transcript_delta = callback_on_transcript_delta
        self.callback_on_response_done = callback_on_response_done
        self.callback_on_error = callback_on_error

        # éŸ³é¢‘é…ç½®
        self.audio_sample_rate = 24000
        self.audio_channels = 1
        self.audio_dtype = np.int16

        # åˆå§‹åŒ–éŸ³é¢‘æµ
        self._init_audio_stream()

        print(f"[RealtimeVoice] åˆå§‹åŒ–æˆåŠŸ")
        print(f"[RealtimeVoice] ç«¯ç‚¹: {azure_endpoint}")
        print(f"[RealtimeVoice] éƒ¨ç½²: {deployment_name}")
        print(f"[RealtimeVoice] è¯­éŸ³: {voice}")

    def _init_audio_stream(self):
        """åˆå§‹åŒ– sounddevice éŸ³é¢‘æµ"""
        try:
            self.audio_stream = sd.OutputStream(
                samplerate=self.audio_sample_rate,
                channels=self.audio_channels,
                dtype=self.audio_dtype,
                blocksize=4096
            )
            self.audio_stream.start()
            print(f"[RealtimeVoice] éŸ³é¢‘æµåˆå§‹åŒ–: {self.audio_sample_rate}Hz, 16-bit PCM")
        except Exception as e:
            print(f"[RealtimeVoice] éŸ³é¢‘æµåˆå§‹åŒ–å¤±è´¥: {e}")
            self.audio_stream = None

    def update_system_prompt(self, new_prompt: str):
        """æ›´æ–°ç³»ç»Ÿæç¤ºè¯"""
        self.system_prompt = new_prompt
        print(f"[RealtimeVoice] System Prompt å·²æ›´æ–°: {new_prompt[:100]}...")

    async def chat(self, user_message: str, conversation_history: list = None):
        """
        å‘é€æ¶ˆæ¯å¹¶æ¥æ”¶æµå¼éŸ³é¢‘å“åº”

        Args:
            user_message: ç”¨æˆ·æ¶ˆæ¯
            conversation_history: å¯¹è¯å†å² [{"role": "user/assistant", "content": "..."}]

        Returns:
            å®Œæ•´çš„ AI å›å¤æ–‡æœ¬ï¼ˆè½¬å½•ï¼‰
        """
        try:
            # åˆ›å»º WebSocket å®¢æˆ·ç«¯
            base_url = self.azure_endpoint.replace("https://", "wss://").rstrip("/") + "/openai/v1"

            realtime_client = AsyncOpenAI(
                websocket_base_url=base_url,
                api_key=self.azure_api_key
            )

            print(f"[RealtimeVoice] è¿æ¥åˆ°: {base_url}")

            # åˆ›å»ºå¼‚æ­¥éŸ³é¢‘é˜Ÿåˆ—
            audio_queue = asyncio.Queue()

            # å¯åŠ¨éŸ³é¢‘æ’­æ”¾åç¨‹
            async def audio_player():
                """åå°æ’­æ”¾éŸ³é¢‘"""
                try:
                    while True:
                        audio_data = await audio_queue.get()
                        if audio_data is None:
                            break

                        # æ’­æ”¾éŸ³é¢‘
                        if self.audio_stream:
                            try:
                                audio_array = np.frombuffer(audio_data, dtype=self.audio_dtype)
                                audio_array = audio_array.reshape(-1, 1)

                                loop = asyncio.get_event_loop()
                                await loop.run_in_executor(
                                    None,
                                    self.audio_stream.write,
                                    audio_array
                                )

                                # å›è°ƒï¼šéŸ³é¢‘å—æ’­æ”¾
                                if self.callback_on_audio_chunk:
                                    self.callback_on_audio_chunk(audio_data)

                            except Exception as e:
                                print(f"[RealtimeVoice] éŸ³é¢‘æ’­æ”¾é”™è¯¯: {e}")

                        audio_queue.task_done()
                except Exception as e:
                    print(f"[RealtimeVoice] éŸ³é¢‘æ’­æ”¾å™¨é”™è¯¯: {e}")

            play_task = asyncio.create_task(audio_player())

            # è¿æ¥å¹¶é…ç½® session
            async with realtime_client.realtime.connect(
                model=self.deployment_name,
            ) as connection:
                # é…ç½® session
                await connection.session.update(session={
                    "output_modalities": ["audio"],
                    "audio": {
                        "output": {
                            "voice": self.voice,
                            "format": {
                                "type": "audio/pcm",
                                "rate": 24000,
                            }
                        }
                    }
                })

                print(f"[RealtimeVoice] Session é…ç½®å®Œæˆ")

                # æ·»åŠ  system prompt
                if self.system_prompt:
                    print(f"[RealtimeVoice] æ·»åŠ  system prompt")
                    await connection.conversation.item.create(
                        item={
                            "type": "message",
                            "role": "system",
                            "content": [{"type": "input_text", "text": self.system_prompt}],
                        }
                    )

                # æ·»åŠ å†å²å¯¹è¯
                if conversation_history:
                    print(f"[RealtimeVoice] æ·»åŠ  {len(conversation_history)} æ¡å†å²æ¶ˆæ¯")
                    for msg in conversation_history:
                        await connection.conversation.item.create(
                            item={
                                "type": "message",
                                "role": msg["role"],
                                "content": [{"type": "input_text", "text": msg["content"]}],
                            }
                        )

                # å‘é€å½“å‰ç”¨æˆ·æ¶ˆæ¯
                print(f"[RealtimeVoice] å‘é€ç”¨æˆ·æ¶ˆæ¯: {user_message[:30]}...")
                await connection.conversation.item.create(
                    item={
                        "type": "message",
                        "role": "user",
                        "content": [{"type": "input_text", "text": user_message}],
                    }
                )
                await connection.response.create()

                # å®æ—¶æ¥æ”¶äº‹ä»¶
                full_response = ""
                audio_chunk_count = 0
                first_chunk = True

                async for event in connection:
                    if event.type == "response.output_audio.delta":
                        # éŸ³é¢‘æ•°æ®å—
                        audio_data = base64.b64decode(event.delta)
                        await audio_queue.put(audio_data)

                        audio_chunk_count += 1
                        if first_chunk:
                            first_chunk = False
                            # å›è°ƒï¼šå“åº”å¼€å§‹
                            if self.callback_on_response_start:
                                self.callback_on_response_start()

                    elif event.type == "response.output_audio_transcript.delta":
                        # è½¬å½•æ–‡æœ¬å¢é‡
                        delta_text = event.delta
                        full_response += delta_text

                        # å›è°ƒï¼šè½¬å½•å¢é‡
                        if self.callback_on_transcript_delta:
                            self.callback_on_transcript_delta(delta_text)

                    elif event.type == "response.output_audio_transcript.done":
                        print(f"[RealtimeVoice] è½¬å½•å®Œæˆ: {full_response[:50]}...")

                    elif event.type == "response.done":
                        print(f"[RealtimeVoice] å“åº”å®Œæˆï¼Œå…±æ¥æ”¶ {audio_chunk_count} ä¸ªéŸ³é¢‘å—")
                        break

            # ç­‰å¾…éŸ³é¢‘æ’­æ”¾å®Œæˆ
            await audio_queue.put(None)
            await play_task
            print(f"[RealtimeVoice] éŸ³é¢‘æ’­æ”¾å®Œæˆ")

            # å›è°ƒï¼šå“åº”å®Œæˆ
            if self.callback_on_response_done:
                self.callback_on_response_done(full_response)

            return full_response

        except Exception as e:
            error_msg = f"RealtimeVoice é”™è¯¯: {str(e)}"
            print(f"[RealtimeVoice] {error_msg}")

            # å›è°ƒï¼šé”™è¯¯
            if self.callback_on_error:
                self.callback_on_error(error_msg)

            import traceback
            traceback.print_exc()
            return ""

    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        if self.audio_stream:
            self.audio_stream.stop()
            self.audio_stream.close()
            print(f"[RealtimeVoice] éŸ³é¢‘æµå·²å…³é—­")


# æµ‹è¯•ä»£ç 
async def test_realtime_voice_engine():
    """æµ‹è¯• Realtime Voice Engine"""

    # ä»ç¯å¢ƒå˜é‡è·å–é…ç½®
    azure_endpoint = os.getenv("AZURE_OPENAI_ENDPOINT")
    azure_api_key = os.getenv("AZURE_OPENAI_API_KEY")

    if not azure_endpoint or not azure_api_key:
        print("è¯·è®¾ç½® AZURE_OPENAI_ENDPOINT å’Œ AZURE_OPENAI_API_KEY ç¯å¢ƒå˜é‡")
        return

    # å®šä¹‰å›è°ƒå‡½æ•°
    def on_response_start():
        print("ğŸ”Š AI å¼€å§‹å›å¤...")

    def on_transcript_delta(delta):
        print(delta, end="", flush=True)

    def on_response_done(full_text):
        print(f"\nâœ“ å›å¤å®Œæˆ: {len(full_text)} å­—")

    # åˆ›å»ºå¼•æ“
    engine = RealtimeVoiceEngine(
        azure_endpoint=azure_endpoint,
        azure_api_key=azure_api_key,
        deployment_name="gpt-realtime-mini",
        voice="alloy",
        system_prompt="ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„AIåŠ©æ‰‹ã€‚",
        callback_on_response_start=on_response_start,
        callback_on_transcript_delta=on_transcript_delta,
        callback_on_response_done=on_response_done
    )

    # å¯¹è¯æµ‹è¯•
    print("\n=== æµ‹è¯• 1: ç®€å•å¯¹è¯ ===")
    response1 = await engine.chat("ä½ å¥½ï¼Œä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±")

    print("\n\n=== æµ‹è¯• 2: å¸¦å†å²çš„å¯¹è¯ ===")
    history = [
        {"role": "user", "content": "ä½ å¥½ï¼Œä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±"},
        {"role": "assistant", "content": response1}
    ]
    await engine.chat("ä½ èƒ½åšä»€ä¹ˆï¼Ÿ", conversation_history=history)

    # æ¸…ç†
    engine.cleanup()


if __name__ == "__main__":
    asyncio.run(test_realtime_voice_engine())
