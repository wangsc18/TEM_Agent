#!/usr/bin/env python3
"""
Mini + TTS å¼•æ“ - ä¿åº•è¯­éŸ³äº¤äº’æ–¹æ¡ˆ
ä½¿ç”¨ gpt-4o-mini (æ–‡æœ¬ç”Ÿæˆ) + edge-tts (æµå¼TTS) + sounddevice (éŸ³é¢‘æ’­æ”¾)
"""
import os
import asyncio
import re
import io
from typing import Optional, List, Dict

import numpy as np
import sounddevice as sd
import soundfile as sf
import edge_tts
from openai import AsyncOpenAI


class MiniTTSEngine:
    """gpt-4o-mini + edge-tts æµå¼å¼•æ“ï¼ˆä¿åº•æ–¹æ¡ˆï¼‰"""

    def __init__(
        self,
        api_key: str,
        base_url: str,
        model: str = "gpt-4o-mini",
        voice: str = "zh-CN-XiaoxiaoNeural",
        system_prompt: str = "",
        temperature: float = 0.7,
        max_tokens: int = 1000,
        callback_on_response_start=None,
        callback_on_text_delta=None,
        callback_on_tts_sentence=None,
        callback_on_response_done=None,
        callback_on_error=None
    ):
        """
        åˆå§‹åŒ– Mini+TTS å¼•æ“

        Args:
            api_key: OpenAI API å¯†é’¥
            base_url: API Base URL
            model: æ¨¡å‹åç§°ï¼ˆé»˜è®¤ gpt-4o-miniï¼‰
            voice: edge-tts è¯­éŸ³ï¼ˆé»˜è®¤ä¸­æ–‡å¥³å£°ï¼‰
            system_prompt: ç³»ç»Ÿæç¤ºè¯
            temperature: æ¸©åº¦å‚æ•°
            max_tokens: æœ€å¤§ token æ•°
            callback_on_response_start: å“åº”å¼€å§‹å›è°ƒ
            callback_on_text_delta: æ–‡æœ¬å¢é‡å›è°ƒ (delta_text)
            callback_on_tts_sentence: TTS å¥å­è½¬æ¢å›è°ƒ (sentence, index, status)
            callback_on_response_done: å“åº”å®Œæˆå›è°ƒ (full_text)
            callback_on_error: é”™è¯¯å›è°ƒ (error_message)
        """
        self.api_key = api_key
        self.model = model
        self.voice = voice
        self.system_prompt = system_prompt
        self.temperature = temperature
        self.max_tokens = max_tokens

        # å¤„ç† base_url
        if not base_url.startswith("http"):
            base_url = f"https://{base_url}"
        if not base_url.endswith("/v1"):
            base_url = f"{base_url}/v1"

        self.base_url = base_url

        # å›è°ƒå‡½æ•°
        self.callback_on_response_start = callback_on_response_start
        self.callback_on_text_delta = callback_on_text_delta
        self.callback_on_tts_sentence = callback_on_tts_sentence
        self.callback_on_response_done = callback_on_response_done
        self.callback_on_error = callback_on_error

        # åˆ›å»º OpenAI å®¢æˆ·ç«¯
        self.client = AsyncOpenAI(
            api_key=api_key,
            base_url=base_url
        )

        # éŸ³é¢‘é…ç½®
        self.audio_sample_rate = 24000  # edge-tts é»˜è®¤é‡‡æ ·ç‡
        self.audio_channels = 1
        self.audio_dtype = np.int16

        # åˆå§‹åŒ–éŸ³é¢‘æµ
        self._init_audio_stream()

        print(f"[MiniTTS] åˆå§‹åŒ–æˆåŠŸ")
        print(f"[MiniTTS] Base URL: {base_url}")
        print(f"[MiniTTS] æ¨¡å‹: {model}")
        print(f"[MiniTTS] è¯­éŸ³: {voice}")
        print(f"[MiniTTS] Temperature: {temperature}")
        print(f"[MiniTTS] Max Tokens: {max_tokens}")

    def _init_audio_stream(self):
        """åˆå§‹åŒ– sounddevice éŸ³é¢‘æµ"""
        try:
            self.audio_stream = sd.OutputStream(
                samplerate=self.audio_sample_rate,
                channels=self.audio_channels,
                dtype=self.audio_dtype,
                blocksize=4096
            )
            self.audio_stream.start()
            print(f"[MiniTTS] éŸ³é¢‘æµåˆå§‹åŒ–: {self.audio_sample_rate}Hz, 16-bit PCM")
        except Exception as e:
            print(f"[MiniTTS] éŸ³é¢‘æµåˆå§‹åŒ–å¤±è´¥: {e}")
            self.audio_stream = None

    def update_system_prompt(self, new_prompt: str):
        """æ›´æ–°ç³»ç»Ÿæç¤ºè¯"""
        self.system_prompt = new_prompt
        print(f"[MiniTTS] System Prompt å·²æ›´æ–°: {new_prompt[:100]}...")

    async def chat(
        self,
        user_message: str,
        conversation_history: Optional[List[Dict[str, str]]] = None
    ) -> str:
        """
        å‘é€æ¶ˆæ¯å¹¶æ¥æ”¶æµå¼å“åº”ï¼ˆæ–‡æœ¬ + è¯­éŸ³ï¼‰

        Args:
            user_message: ç”¨æˆ·æ¶ˆæ¯
            conversation_history: å¯¹è¯å†å² [{\"role\": \"user/assistant\", \"content\": \"...\"}]

        Returns:
            å®Œæ•´çš„ AI å›å¤æ–‡æœ¬
        """
        try:
            # æ„å»ºæ¶ˆæ¯åˆ—è¡¨
            messages = []

            # æ·»åŠ  system prompt
            if self.system_prompt:
                messages.append({
                    "role": "system",
                    "content": self.system_prompt
                })

            # æ·»åŠ å†å²å¯¹è¯
            if conversation_history:
                messages.extend(conversation_history)

            # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
            messages.append({
                "role": "user",
                "content": user_message
            })

            print(f"[MiniTTS] å‘é€æ¶ˆæ¯: {user_message[:50]}...")
            print(f"[MiniTTS] æ¶ˆæ¯æ€»æ•°: {len(messages)} æ¡")

            # è°ƒç”¨æµå¼ API
            return await self._chat_streaming_with_tts(messages)

        except Exception as e:
            error_msg = f"MiniTTS é”™è¯¯: {str(e)}"
            print(f"[MiniTTS] {error_msg}")

            # å›è°ƒï¼šé”™è¯¯
            if self.callback_on_error:
                self.callback_on_error(error_msg)

            import traceback
            traceback.print_exc()
            return ""

    async def _chat_streaming_with_tts(self, messages: List[Dict[str, str]]) -> str:
        """æµå¼å¯¹è¯ + å®æ—¶ TTS"""
        full_response = ""
        first_chunk = True

        # å¥å­ç¼“å†²åŒº
        sentence_buffer = ""
        sentence_index = 0

        # éŸ³é¢‘å­˜å‚¨å­—å…¸ {sentence_index: [audio_chunks]}
        audio_storage = {}
        audio_storage_lock = asyncio.Lock()

        # å¥å­å®Œæˆäº‹ä»¶ {sentence_index: Event}
        sentence_ready_events = {}

        # å¯åŠ¨éŸ³é¢‘æ’­æ”¾å™¨ï¼ˆæŒ‰é¡ºåºæ’­æ”¾ï¼‰
        async def audio_player(total_sentences):
            """åå°æ’­æ”¾éŸ³é¢‘ - æŒ‰å¥å­ç´¢å¼•é¡ºåºæ’­æ”¾"""
            try:
                for expected_index in range(total_sentences):
                    # ç­‰å¾…å½“å‰å¥å­å‡†å¤‡å¥½
                    if expected_index not in sentence_ready_events:
                        sentence_ready_events[expected_index] = asyncio.Event()

                    await sentence_ready_events[expected_index].wait()

                    # ä»å­˜å‚¨ä¸­å–å‡ºéŸ³é¢‘æ•°æ®
                    async with audio_storage_lock:
                        audio_chunks = audio_storage.get(expected_index, [])

                    # æ’­æ”¾æ‰€æœ‰éŸ³é¢‘å—
                    if self.audio_stream and audio_chunks:
                        for audio_data in audio_chunks:
                            try:
                                # å°†å­—èŠ‚æ•°æ®è½¬æ¢ä¸º numpy æ•°ç»„
                                audio_array = np.frombuffer(audio_data, dtype=self.audio_dtype)
                                if len(audio_array) > 0:
                                    audio_array = audio_array.reshape(-1, 1)

                                    loop = asyncio.get_event_loop()
                                    await loop.run_in_executor(
                                        None,
                                        self.audio_stream.write,
                                        audio_array
                                    )
                            except Exception as e:
                                print(f"[MiniTTS] éŸ³é¢‘æ’­æ”¾é”™è¯¯: {e}")

                    print(f"[MiniTTS] å¥å­ #{expected_index} æ’­æ”¾å®Œæˆ")

            except Exception as e:
                print(f"[MiniTTS] éŸ³é¢‘æ’­æ”¾å™¨é”™è¯¯: {e}")

        # TTS ä»»åŠ¡é˜Ÿåˆ—
        tts_tasks = []

        async def process_sentence(sentence: str, index: int):
            """å¤„ç†å•ä¸ªå¥å­çš„ TTS"""
            if not sentence.strip():
                return

            # æ¸…ç† Markdown æ ‡è®°
            clean_sentence = self._clean_markdown(sentence)
            if not clean_sentence.strip():
                # æ¸…ç†åä¸ºç©ºï¼Œè·³è¿‡
                if index not in sentence_ready_events:
                    sentence_ready_events[index] = asyncio.Event()
                sentence_ready_events[index].set()
                return

            print(f"[MiniTTS] TTS å¥å­ #{index}: {clean_sentence[:30]}...")

            # å›è°ƒï¼šTTS å¼€å§‹
            if self.callback_on_tts_sentence:
                self.callback_on_tts_sentence(clean_sentence, index, "converting")

            try:
                # edge-tts è½¬æ¢ - æ”¶é›†æ‰€æœ‰éŸ³é¢‘å—
                communicate = edge_tts.Communicate(clean_sentence, self.voice)
                audio_bytes = b""

                async for chunk in communicate.stream():
                    if chunk["type"] == "audio":
                        audio_bytes += chunk["data"]

                if not audio_bytes:
                    print(f"[MiniTTS] è­¦å‘Šï¼šå¥å­ #{index} æ²¡æœ‰ç”ŸæˆéŸ³é¢‘æ•°æ®")
                    # ä»ç„¶è®¾ç½®äº‹ä»¶ï¼Œé¿å…æ’­æ”¾å™¨å¡ä½
                    if index not in sentence_ready_events:
                        sentence_ready_events[index] = asyncio.Event()
                    sentence_ready_events[index].set()
                    return

                # ä½¿ç”¨ soundfile è§£ç éŸ³é¢‘æ•°æ®ï¼ˆedge-tts è¾“å‡º MP3 æ ¼å¼ï¼‰
                audio_buffer = io.BytesIO(audio_bytes)

                # è¯»å–éŸ³é¢‘æ•°æ®
                audio_data, sample_rate = sf.read(audio_buffer, dtype='float32')

                print(f"[MiniTTS] éŸ³é¢‘è§£ç : {len(audio_data)} é‡‡æ ·ç‚¹, {sample_rate}Hz")

                # å›è°ƒï¼šTTS æ’­æ”¾ï¼ˆæ³¨æ„ï¼šè¿™é‡Œåªæ˜¯æ ‡è®°å‡†å¤‡å¥½ï¼Œå®é™…æ’­æ”¾æŒ‰é¡ºåºï¼‰
                if self.callback_on_tts_sentence:
                    self.callback_on_tts_sentence(clean_sentence, index, "queued")

                # å°†éŸ³é¢‘æ•°æ®å¤„ç†å¹¶å­˜å‚¨
                # è½¬æ¢ä¸º int16 æ ¼å¼ï¼ˆsounddevice éœ€è¦ï¼‰
                if audio_data.ndim == 1:
                    # å•å£°é“
                    audio_data = audio_data.reshape(-1, 1)
                elif audio_data.ndim == 2 and audio_data.shape[1] == 2:
                    # ç«‹ä½“å£°ï¼Œè½¬ä¸ºå•å£°é“
                    audio_data = audio_data.mean(axis=1, keepdims=True)

                # é‡é‡‡æ ·åˆ°ç›®æ ‡é‡‡æ ·ç‡ï¼ˆå¦‚æœéœ€è¦ï¼‰
                if sample_rate != self.audio_sample_rate:
                    print(f"[MiniTTS] é‡é‡‡æ ·: {sample_rate}Hz -> {self.audio_sample_rate}Hz")
                    # ç®€å•çš„çº¿æ€§æ’å€¼é‡é‡‡æ ·
                    ratio = self.audio_sample_rate / sample_rate
                    new_length = int(len(audio_data) * ratio)
                    audio_data = np.interp(
                        np.linspace(0, len(audio_data) - 1, new_length),
                        np.arange(len(audio_data)),
                        audio_data.flatten()
                    ).reshape(-1, 1)

                # è½¬æ¢ä¸º int16
                audio_int16 = (audio_data * 32767).astype(np.int16)

                # åˆ†å—å­˜å‚¨åˆ°å­—å…¸
                chunk_size = 4096
                audio_chunks = []
                for i in range(0, len(audio_int16), chunk_size):
                    chunk = audio_int16[i:i + chunk_size]
                    audio_chunks.append(chunk.tobytes())

                # å­˜å‚¨åˆ°å­—å…¸å¹¶è®¾ç½®äº‹ä»¶
                async with audio_storage_lock:
                    audio_storage[index] = audio_chunks

                # ç¡®ä¿äº‹ä»¶å­˜åœ¨å¹¶è®¾ç½®
                if index not in sentence_ready_events:
                    sentence_ready_events[index] = asyncio.Event()
                sentence_ready_events[index].set()

                print(f"[MiniTTS] TTS å¥å­ #{index} è½¬æ¢å®Œæˆ")

            except Exception as e:
                print(f"[MiniTTS] TTS é”™è¯¯ (å¥å­ #{index}): {e}")
                import traceback
                traceback.print_exc()
                # å‡ºé”™æ—¶ä¹Ÿè¦è®¾ç½®äº‹ä»¶ï¼Œé¿å…æ’­æ”¾å™¨å¡ä½
                if index not in sentence_ready_events:
                    sentence_ready_events[index] = asyncio.Event()
                sentence_ready_events[index].set()

        # å¼€å§‹æµå¼ç”Ÿæˆ
        stream = await self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            stream=True,
            temperature=self.temperature,
            max_tokens=self.max_tokens
        )

        async for chunk in stream:
            if chunk.choices[0].delta.content:
                delta = chunk.choices[0].delta.content
                full_response += delta
                sentence_buffer += delta

                if first_chunk:
                    first_chunk = False
                    # å›è°ƒï¼šå“åº”å¼€å§‹
                    if self.callback_on_response_start:
                        self.callback_on_response_start()

                # å›è°ƒï¼šæ–‡æœ¬å¢é‡
                if self.callback_on_text_delta:
                    self.callback_on_text_delta(delta)

                # æ£€æŸ¥æ˜¯å¦æœ‰å®Œæ•´çš„å¥å­
                sentences = self._split_sentences(sentence_buffer)
                if len(sentences) > 1:
                    # å¤„ç†é™¤æœ€åä¸€ä¸ªä¹‹å¤–çš„æ‰€æœ‰å¥å­ï¼ˆæœ€åä¸€ä¸ªå¯èƒ½ä¸å®Œæ•´ï¼‰
                    for sentence in sentences[:-1]:
                        if sentence.strip():
                            # åˆ›å»º TTS ä»»åŠ¡
                            task = asyncio.create_task(process_sentence(sentence, sentence_index))
                            tts_tasks.append(task)
                            sentence_index += 1

                    # ä¿ç•™æœ€åä¸€ä¸ªæœªå®Œæˆçš„å¥å­
                    sentence_buffer = sentences[-1]

        # å¤„ç†æœ€åå‰©ä½™çš„æ–‡æœ¬
        if sentence_buffer.strip():
            task = asyncio.create_task(process_sentence(sentence_buffer, sentence_index))
            tts_tasks.append(task)
            sentence_index += 1

        print(f"[MiniTTS] æ–‡æœ¬ç”Ÿæˆå®Œæˆ: {len(full_response)} å­—ç¬¦")

        # è®¡ç®—æ€»å¥å­æ•°
        total_sentences = sentence_index

        if total_sentences > 0:
            # å¯åŠ¨æ’­æ”¾å™¨ï¼ˆéœ€è¦çŸ¥é“æ€»å¥å­æ•°ï¼‰
            play_task = asyncio.create_task(audio_player(total_sentences))

            # ç­‰å¾…æ‰€æœ‰ TTS ä»»åŠ¡å®Œæˆ
            if tts_tasks:
                await asyncio.gather(*tts_tasks)

            # ç­‰å¾…éŸ³é¢‘æ’­æ”¾å®Œæˆ
            await play_task
        else:
            print(f"[MiniTTS] æ²¡æœ‰ç”Ÿæˆä»»ä½•å¥å­")

        print(f"[MiniTTS] éŸ³é¢‘æ’­æ”¾å®Œæˆ")

        # å›è°ƒï¼šå“åº”å®Œæˆ
        if self.callback_on_response_done:
            self.callback_on_response_done(full_response)

        return full_response

    def _split_sentences(self, text: str) -> List[str]:
        """
        åˆ†å‰²å¥å­ï¼ˆä¸­æ–‡å’Œè‹±æ–‡ï¼‰

        Args:
            text: è¾“å…¥æ–‡æœ¬

        Returns:
            å¥å­åˆ—è¡¨
        """
        # ä½¿ç”¨æ­£åˆ™è¡¨è¾¾å¼åˆ†å‰²å¥å­ï¼ˆä¿ç•™åˆ†éš”ç¬¦ï¼‰
        # ä¸­æ–‡ï¼šã€‚ï¼ï¼Ÿ\n
        # è‹±æ–‡ï¼š. ! ? \n
        pattern = r'([ã€‚ï¼ï¼Ÿ.!?\n]+)'
        parts = re.split(pattern, text)

        # é‡æ–°ç»„åˆå¥å­ï¼ˆå°†åˆ†éš”ç¬¦é™„åŠ åˆ°å‰ä¸€ä¸ªå¥å­ï¼‰
        sentences = []
        for i in range(0, len(parts) - 1, 2):
            if i + 1 < len(parts):
                sentences.append(parts[i] + parts[i + 1])
            else:
                sentences.append(parts[i])

        # æ·»åŠ æœ€åä¸€ä¸ªéƒ¨åˆ†ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        if len(parts) % 2 == 1:
            sentences.append(parts[-1])

        return sentences

    def _clean_markdown(self, text: str) -> str:
        """
        æ¸…ç† Markdown æ ¼å¼æ ‡è®°ï¼Œä½¿æ–‡æœ¬é€‚åˆ TTS

        Args:
            text: åŒ…å« Markdown æ ‡è®°çš„æ–‡æœ¬

        Returns:
            æ¸…ç†åçš„çº¯æ–‡æœ¬
        """
        # 1. ç§»é™¤ç²—ä½“å’Œæ–œä½“æ ‡è®°
        # **ç²—ä½“** æˆ– __ç²—ä½“__
        text = re.sub(r'\*\*(.+?)\*\*', r'\1', text)
        text = re.sub(r'__(.+?)__', r'\1', text)
        # *æ–œä½“* æˆ– _æ–œä½“_
        text = re.sub(r'\*(.+?)\*', r'\1', text)
        text = re.sub(r'_(.+?)_', r'\1', text)

        # 2. ç§»é™¤ä»£ç æ ‡è®°
        # `ä»£ç `
        text = re.sub(r'`(.+?)`', r'\1', text)
        # ```ä»£ç å—```
        text = re.sub(r'```[\s\S]*?```', '', text)

        # 3. ç§»é™¤åˆ é™¤çº¿
        # ~~åˆ é™¤çº¿~~
        text = re.sub(r'~~(.+?)~~', r'\1', text)

        # 4. ç§»é™¤æ ‡é¢˜æ ‡è®°
        # # æ ‡é¢˜
        text = re.sub(r'^#+\s*', '', text, flags=re.MULTILINE)

        # 5. ç§»é™¤åˆ—è¡¨æ ‡è®°
        # - åˆ—è¡¨é¡¹ æˆ– * åˆ—è¡¨é¡¹ æˆ– æ•°å­—. åˆ—è¡¨é¡¹
        text = re.sub(r'^\s*[-*+]\s+', '', text, flags=re.MULTILINE)
        text = re.sub(r'^\s*\d+\.\s+', '', text, flags=re.MULTILINE)

        # 6. ç§»é™¤é“¾æ¥ï¼Œä¿ç•™æ–‡æœ¬
        # [æ–‡æœ¬](url)
        text = re.sub(r'\[(.+?)\]\(.+?\)', r'\1', text)

        # 7. ç§»é™¤å›¾ç‰‡
        # ![alt](url)
        text = re.sub(r'!\[.*?\]\(.+?\)', '', text)

        # 8. ç§»é™¤å¼•ç”¨æ ‡è®°
        # > å¼•ç”¨
        text = re.sub(r'^\s*>\s*', '', text, flags=re.MULTILINE)

        # 9. ç§»é™¤æ°´å¹³çº¿
        # --- æˆ– *** æˆ– ___
        text = re.sub(r'^[-*_]{3,}\s*$', '', text, flags=re.MULTILINE)

        # 10. ç§»é™¤å¤šä½™çš„ç©ºè¡Œ
        text = re.sub(r'\n{3,}', '\n\n', text)

        # 11. ç§»é™¤é¦–å°¾ç©ºç™½
        text = text.strip()

        return text

    def cleanup(self):
        """æ¸…ç†èµ„æº"""
        if self.audio_stream:
            self.audio_stream.stop()
            self.audio_stream.close()
            print(f"[MiniTTS] éŸ³é¢‘æµå·²å…³é—­")


# æµ‹è¯•ä»£ç 
async def test_mini_tts_engine():
    """æµ‹è¯• Mini+TTS Engine"""

    # ä»ç¯å¢ƒå˜é‡è·å–é…ç½®
    api_key = os.getenv("OPENAI_API_KEY")
    base_url = "https://yunwu.zeabur.app"

    if not api_key:
        print("è¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
        return

    # å®šä¹‰å›è°ƒå‡½æ•°
    def on_response_start():
        print("\nğŸ¤– AI å¼€å§‹å›å¤...")

    def on_text_delta(delta):
        print(delta, end="", flush=True)

    def on_tts_sentence(sentence, index, status):
        status_map = {
            "converting": "â³ TTSè½¬æ¢",
            "playing": "ğŸ”Š æ’­æ”¾ä¸­"
        }
        status_text = status_map.get(status, status)
        print(f"\n[{status_text}] å¥å­ #{index}: {sentence[:25]}...")

    def on_response_done(full_text):
        print(f"\n\nâœ“ å›å¤å®Œæˆ: {len(full_text)} å­—ç¬¦")

    # åˆ›å»ºå¼•æ“
    engine = MiniTTSEngine(
        api_key=api_key,
        base_url=base_url,
        model="gpt-4o-mini",
        voice="zh-CN-XiaoxiaoNeural",
        system_prompt="ä½ æ˜¯ä¸€åèˆªç©ºé£è¡Œå‘˜AIä¼™ä¼´ï¼Œæ­£åœ¨ä¸å¦ä¸€åé£è¡Œå‘˜è¿›è¡ŒTEMï¼ˆå¨èƒä¸å·®é”™ç®¡ç†ï¼‰æ¡ˆä¾‹è®¨è®ºã€‚ç”¨ç®€çŸ­ã€å£è¯­åŒ–çš„æ–¹å¼å›ç­”ï¼ˆ10-20å­—ï¼‰ã€‚",
        temperature=0.7,
        max_tokens=1000,
        callback_on_response_start=on_response_start,
        callback_on_text_delta=on_text_delta,
        callback_on_tts_sentence=on_tts_sentence,
        callback_on_response_done=on_response_done
    )

    # å¯¹è¯æµ‹è¯•
    print("\n=== æµ‹è¯• 1: ç®€å•å¯¹è¯ ===")
    response1 = await engine.chat("ä½ å¥½ï¼Œä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±")

    print("\n\n=== æµ‹è¯• 2: å¸¦å†å²çš„å¯¹è¯ ===")
    history = [
        {"role": "user", "content": "ä½ å¥½ï¼Œä»‹ç»ä¸€ä¸‹ä½ è‡ªå·±"},
        {"role": "assistant", "content": response1}
    ]
    await engine.chat("APUæ•…éšœä¼šå½±å“èµ·é£å—ï¼Ÿ", conversation_history=history)

    # æ¸…ç†
    engine.cleanup()
    print("\nâœ“ æµ‹è¯•å®Œæˆ")


if __name__ == "__main__":
    import asyncio
    asyncio.run(test_mini_tts_engine())
